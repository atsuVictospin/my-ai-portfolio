{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1a46e8-0128-4d8d-81a6-d48a91cbcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 17.7557\n",
      "Epoch [2/5], Loss: 17.0032\n",
      "Epoch [3/5], Loss: 16.8056\n",
      "Epoch [4/5], Loss: 15.7895\n",
      "Epoch [5/5], Loss: 15.0679\n",
      "Accuracy: 70.07299270072993 %\n"
     ]
    }
   ],
   "source": [
    "# ライブラリを読み込みます（AIや画像処理をするための道具箱を使えるようにする）\n",
    "import torch            # PyTorch本体\n",
    "import torch.nn as nn   # ニューラルネットワーク用の部品\n",
    "import torch.optim as optim   # 学習アルゴリズム（重みを調整する仕組み）\n",
    "from torchvision import datasets, transforms, models  # 画像データや変換などのツール集\n",
    "from torch.utils.data import DataLoader   # 画像を小分けにしてまとめて渡す道具\n",
    "\n",
    "# 画像を同じ大きさにリサイズし、0〜1の範囲で扱えるように変換する（前準備）\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # 画像の大きさを128×128に\n",
    "    transforms.ToTensor()           # 0〜1の数値の配列に変換\n",
    "])\n",
    "\n",
    "# 学習用とテスト用の画像フォルダからデータを読み込む（パソコンのフォルダ名に合わせる）\n",
    "#train_data = datasets.ImageFolder(\"dataset/train\", transform=transform)\n",
    "#test_data = datasets.ImageFolder(\"dataset/test\", transform=transform)\n",
    "train_data = datasets.ImageFolder(R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\train\", transform=transform)\n",
    "test_data = datasets.ImageFolder(R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\val\", transform=transform)\n",
    "\n",
    "\n",
    "# 画像データを8枚ずつまとめてメモリに取り込む（小分けにしてAIに渡すための仕組み）\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8)\n",
    "\n",
    "# ニューラルネット（ここでは畳み込みニューラルネット：CNN）を自分で定義する\n",
    "class SimpleCNN(nn.Module):  # AIの本体「型」を作る\n",
    "    def __init__(self):\n",
    "        super().__init__()  # 親クラスの初期化\n",
    "        # 画像特徴を取り出す部分\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), # 入力3色→16個のフィルタ。小さい四角（3x3）で切り取る\n",
    "            nn.ReLU(),                      # マイナスを0に、プラスはそのまま（活性化関数）\n",
    "            nn.MaxPool2d(2, 2),             # 2×2の中で最大値だけ通す（サイズを半分に）\n",
    "            nn.Conv2d(16, 32, 3, padding=1), # さらに32フィルタへ\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)              # さらに半分（合計で4分の1サイズに）\n",
    "        )\n",
    "        # 画像特徴→「どちらか」（良品／不良品）を決める部分\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32*32*32, 64),  # 32チャンネル×32×32画素→64個の数に縮める\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)          # 最後に2つ：ラベル（良品、不良品）のどちらか\n",
    "        )\n",
    "\n",
    "    def forward(self, x):    # 画像を渡されたとき処理するやり方を書く\n",
    "        x = self.conv(x)     # 「特徴を抽出」部分\n",
    "        x = x.view(-1, 32*32*32)  # 配列の形を1列に整える\n",
    "        x = self.fc(x)       # 「結果を出す」部分に通す\n",
    "        return x             # 結果（良品／不良品の可能性）を返す\n",
    "\n",
    "# 作ったAIモデルの箱を用意する\n",
    "model = SimpleCNN()  \n",
    "# GPU（高速な計算機）があれば使う設定、なければ普通のCPUを使う\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # モデルを計算機に渡す\n",
    "\n",
    "# AIがどれだけ間違えたか測る方法を決める（損失関数）、重みをどう調整するかも決める\n",
    "criterion = nn.CrossEntropyLoss()  # 複数分類用の標準的な測り方\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 学習する方法\n",
    "\n",
    "# ここからAIの「学習」を実行する（データを何回も見せて更新）\n",
    "for epoch in range(5):  # 5回（エポック）くり返す\n",
    "    running_loss = 0.0   # 各エポックの誤差を最初0にする\n",
    "    for images, labels in train_loader:    # 8枚ずつ画像＆答えをもらう\n",
    "        images, labels = images.to(device), labels.to(device)  # GPUまたはCPUに渡す\n",
    "\n",
    "        optimizer.zero_grad()  # 前回の計算の残りをリセット\n",
    "        outputs = model(images)  # 画像をモデルに入れて予測値を出す\n",
    "        loss = criterion(outputs, labels)  # 予測と正解の差（損失）を計算\n",
    "        loss.backward()                    # どこを直すべきか計算\n",
    "        optimizer.step()                   # 計算結果にもとづいてモデルを少し修正\n",
    "        running_loss += loss.item()        # 誤差を足し合わせる\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss:.4f}\")  # 何回めで誤差がどれくらいか表示\n",
    "\n",
    "# 学習したAIがどれだけ正しく答えられるかをテストする\n",
    "correct = 0  # 正解数を0でリセット\n",
    "total = 0    # 全体数も0でリセット\n",
    "model.eval()  # 評価モード（途中で重み変更なし）\n",
    "with torch.no_grad():         # 勝手に勾配を計算しないように\n",
    "    for images, labels in test_loader:   # テスト画像を8枚ずつ処理\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)            # モデルで予測\n",
    "        _, predicted = torch.max(outputs, 1)    # 予測結果の中で一番大きい番号＝予測ラベル\n",
    "        total += labels.size(0)            # 全体のラベル数を足す\n",
    "        correct += (predicted == labels).sum().item()  # 予測が当たったものを数える\n",
    "print(\"Accuracy:\", 100 * correct / total, \"%\")      # 正解率をパーセントで表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd00eb-07c0-47a6-b115-dacf36a935a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-env)",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
