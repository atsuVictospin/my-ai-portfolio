{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1952a34d-d26a-4e26-a08c-26d15d840ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "名前変更が完了しました。\n"
     ]
    }
   ],
   "source": [
    "import os  # OSのファイル操作モジュールを読み込みます\n",
    "\n",
    "folder_path = R\"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\val\\nagative\"\n",
    "# 対象のフォルダパスを設定してください\n",
    "\n",
    "# フォルダ内の全ファイル名を取得してループで処理\n",
    "for filename in os.listdir(folder_path):\n",
    "    base, ext = os.path.splitext(filename)  # ファイル名と拡張子を分けます\n",
    "    new_name = base + \"3\" + ext  # ファイル名の最後に\"1\"を追加します\n",
    "    old_file = os.path.join(folder_path, filename)  # 元ファイルのフルパス\n",
    "    new_file = os.path.join(folder_path, new_name)  # 新ファイル名のフルパス\n",
    "    os.rename(old_file, new_file)  # ファイル名を変更します\n",
    "\n",
    "print(\"名前変更が完了しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7499cfd-dbee-4f7f-a216-949f2384455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての画像の前処理（リサイズ・正規化）を終えました。\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image  # 画像を扱うためのライブラリPillowを読み込みます\n",
    "import numpy as np  # 数値計算用のライブラリNumPyを読み込みます\n",
    "import os  # ファイル操作・フォルダ操作用のモジュールを読み込みます\n",
    "\n",
    "folder_path = R\"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\val\\nagative\" # 画像が入っているフォルダの名前（適宜変更してください）\n",
    "output_folder = R\"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\val\\negative_processed_images\"  # 処理後の画像を保存するフォルダ名です\n",
    "\n",
    "if not os.path.exists(output_folder):  # 出力用フォルダがなければ\n",
    "    os.makedirs(output_folder)  # 新しくフォルダを作成します\n",
    "\n",
    "for filename in os.listdir(folder_path):  # フォルダ内のすべてのファイルに対して繰り返します\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # jpgまたはpngファイルだけ処理対象にします\n",
    "        img_path = os.path.join(folder_path, filename)  # 元画像ファイルのフルパスを作ります\n",
    "        img = Image.open(img_path)  # 画像を開きます\n",
    "\n",
    "        img_resized = img.resize((700, 700))  # 画像のサイズを64×64ピクセルに統一してリサイズします\n",
    "\n",
    "        img_array = np.array(img_resized)  # 画像を数値の配列（NumPy配列）に変換します\n",
    "\n",
    "        img_normalized = img_array / 255.0  # ピクセルの値を0〜1に正規化します（255で割る）\n",
    "\n",
    "        img_normalized = (img_normalized * 255).astype(np.uint8)  # 再び255スケールに戻して整数化（保存用）\n",
    "\n",
    "        img_final = Image.fromarray(img_normalized)  # NumPy配列からPillowの画像オブジェクトに戻します\n",
    "\n",
    "        save_path = os.path.join(output_folder, filename)  # 保存先のパスを作ります\n",
    "        img_final.save(save_path)  # 正規化・リサイズした画像を保存します\n",
    "\n",
    "print(\"すべての画像の前処理（リサイズ・正規化）を終えました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff159943-b752-46c4-aa8d-d2ca82cef397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての画像の前処理（リサイズ・正規化）を終えました。\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image  # 画像を扱うためのライブラリPillowを読み込みます\n",
    "import numpy as np  # 数値計算用のライブラリNumPyを読み込みます\n",
    "import os  # ファイル操作・フォルダ操作用のモジュールを読み込みます\n",
    "\n",
    "folder_path = R\"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\val\\positive\" # 画像が入っているフォルダの名前（適宜変更してください）\n",
    "output_folder = R\"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\val\\positive_processed_images\"  # 処理後の画像を保存するフォルダ名です\n",
    "\n",
    "if not os.path.exists(output_folder):  # 出力用フォルダがなければ\n",
    "    os.makedirs(output_folder)  # 新しくフォルダを作成します\n",
    "\n",
    "for filename in os.listdir(folder_path):  # フォルダ内のすべてのファイルに対して繰り返します\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # jpgまたはpngファイルだけ処理対象にします\n",
    "        img_path = os.path.join(folder_path, filename)  # 元画像ファイルのフルパスを作ります\n",
    "        img = Image.open(img_path)  # 画像を開きます\n",
    "\n",
    "        img_resized = img.resize((700, 700))  # 画像のサイズを64×64ピクセルに統一してリサイズします\n",
    "\n",
    "        img_array = np.array(img_resized)  # 画像を数値の配列（NumPy配列）に変換します\n",
    "\n",
    "        img_normalized = img_array / 255.0  # ピクセルの値を0〜1に正規化します（255で割る）\n",
    "\n",
    "        img_normalized = (img_normalized * 255).astype(np.uint8)  # 再び255スケールに戻して整数化（保存用）\n",
    "\n",
    "        img_final = Image.fromarray(img_normalized)  # NumPy配列からPillowの画像オブジェクトに戻します\n",
    "\n",
    "        save_path = os.path.join(output_folder, filename)  # 保存先のパスを作ります\n",
    "        img_final.save(save_path)  # 正規化・リサイズした画像を保存します\n",
    "\n",
    "print(\"すべての画像の前処理（リサイズ・正規化）を終えました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c71609-f6d1-462f-9d55-f9e01039ad84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての画像の前処理（リサイズ・正規化）を終えました。\n"
     ]
    }
   ],
   "source": [
    "# \"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\train\\negative\"\n",
    "from PIL import Image  # 画像を扱うためのライブラリPillowを読み込みます\n",
    "import numpy as np  # 数値計算用のライブラリNumPyを読み込みます\n",
    "import os  # ファイル操作・フォルダ操作用のモジュールを読み込みます\n",
    "\n",
    "folder_path = R\"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\train\\negative\" # 画像が入っているフォルダの名前（適宜変更してください）\n",
    "output_folder = R\"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\train\\train_negative_processed_images\"  # 処理後の画像を保存するフォルダ名です\n",
    "\n",
    "if not os.path.exists(output_folder):  # 出力用フォルダがなければ\n",
    "    os.makedirs(output_folder)  # 新しくフォルダを作成します\n",
    "\n",
    "for filename in os.listdir(folder_path):  # フォルダ内のすべてのファイルに対して繰り返します\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # jpgまたはpngファイルだけ処理対象にします\n",
    "        img_path = os.path.join(folder_path, filename)  # 元画像ファイルのフルパスを作ります\n",
    "        img = Image.open(img_path)  # 画像を開きます\n",
    "\n",
    "        img_resized = img.resize((700, 700))  # 画像のサイズを64×64ピクセルに統一してリサイズします\n",
    "\n",
    "        img_array = np.array(img_resized)  # 画像を数値の配列（NumPy配列）に変換します\n",
    "\n",
    "        img_normalized = img_array / 255.0  # ピクセルの値を0〜1に正規化します（255で割る）\n",
    "\n",
    "        img_normalized = (img_normalized * 255).astype(np.uint8)  # 再び255スケールに戻して整数化（保存用）\n",
    "\n",
    "        img_final = Image.fromarray(img_normalized)  # NumPy配列からPillowの画像オブジェクトに戻します\n",
    "\n",
    "        save_path = os.path.join(output_folder, filename)  # 保存先のパスを作ります\n",
    "        img_final.save(save_path)  # 正規化・リサイズした画像を保存します\n",
    "\n",
    "print(\"すべての画像の前処理（リサイズ・正規化）を終えました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2cde6a-4210-44f5-a686-9546a9930be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての画像の前処理（リサイズ・正規化）を終えました。\n"
     ]
    }
   ],
   "source": [
    "# \"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\train\\negative\"\n",
    "from PIL import Image  # 画像を扱うためのライブラリPillowを読み込みます\n",
    "import numpy as np  # 数値計算用のライブラリNumPyを読み込みます\n",
    "import os  # ファイル操作・フォルダ操作用のモジュールを読み込みます\n",
    "\n",
    "folder_path = R\"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\train\\positive\" # 画像が入っているフォルダの名前（適宜変更してください）\n",
    "output_folder = R\"C:\\Users\\AtsukiSakamoto\\Downloads\\metal_nut\\metal_nut\\train\\train_positive_processed_images\"  # 処理後の画像を保存するフォルダ名です\n",
    "\n",
    "if not os.path.exists(output_folder):  # 出力用フォルダがなければ\n",
    "    os.makedirs(output_folder)  # 新しくフォルダを作成します\n",
    "\n",
    "for filename in os.listdir(folder_path):  # フォルダ内のすべてのファイルに対して繰り返します\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # jpgまたはpngファイルだけ処理対象にします\n",
    "        img_path = os.path.join(folder_path, filename)  # 元画像ファイルのフルパスを作ります\n",
    "        img = Image.open(img_path)  # 画像を開きます\n",
    "\n",
    "        img_resized = img.resize((700, 700))  # 画像のサイズを64×64ピクセルに統一してリサイズします\n",
    "\n",
    "        img_array = np.array(img_resized)  # 画像を数値の配列（NumPy配列）に変換します\n",
    "\n",
    "        img_normalized = img_array / 255.0  # ピクセルの値を0〜1に正規化します（255で割る）\n",
    "\n",
    "        img_normalized = (img_normalized * 255).astype(np.uint8)  # 再び255スケールに戻して整数化（保存用）\n",
    "\n",
    "        img_final = Image.fromarray(img_normalized)  # NumPy配列からPillowの画像オブジェクトに戻します\n",
    "\n",
    "        save_path = os.path.join(output_folder, filename)  # 保存先のパスを作ります\n",
    "        img_final.save(save_path)  # 正規化・リサイズした画像を保存します\n",
    "\n",
    "print(\"すべての画像の前処理（リサイズ・正規化）を終えました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb896b0-fa10-43a2-a798-2176e6ac7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('positive\\\\101.png', 0)\n",
      "('positive\\\\102.png', 0)\n",
      "('positive\\\\103.png', 0)\n",
      "('positive\\\\104.png', 0)\n",
      "('positive\\\\105.png', 0)\n",
      "('positive\\\\106.png', 0)\n",
      "('positive\\\\107.png', 0)\n",
      "('positive\\\\108.png', 0)\n",
      "('positive\\\\109.png', 0)\n",
      "('positive\\\\110.png', 0)\n",
      "('positive\\\\111.png', 0)\n",
      "('positive\\\\112.png', 0)\n",
      "('positive\\\\113.png', 0)\n",
      "('positive\\\\114.png', 0)\n",
      "('positive\\\\115.png', 0)\n",
      "('positive\\\\116.png', 0)\n",
      "('positive\\\\117.png', 0)\n",
      "('positive\\\\118.png', 0)\n",
      "('positive\\\\119.png', 0)\n",
      "('positive\\\\120.png', 0)\n",
      "('positive\\\\121.png', 0)\n",
      "('positive\\\\122.png', 0)\n",
      "('positive\\\\123.png', 0)\n",
      "('positive\\\\124.png', 0)\n",
      "('positive\\\\125.png', 0)\n",
      "('positive\\\\126.png', 0)\n",
      "('positive\\\\127.png', 0)\n",
      "('positive\\\\128.png', 0)\n",
      "('positive\\\\129.png', 0)\n",
      "('positive\\\\130.png', 0)\n",
      "('positive\\\\131.png', 0)\n",
      "('positive\\\\132.png', 0)\n",
      "('positive\\\\133.png', 0)\n",
      "('positive\\\\134.png', 0)\n",
      "('positive\\\\135.png', 0)\n",
      "('positive\\\\136.png', 0)\n",
      "('positive\\\\137.png', 0)\n",
      "('positive\\\\138.png', 0)\n",
      "('positive\\\\139.png', 0)\n",
      "('positive\\\\140.png', 0)\n",
      "('positive\\\\141.png', 0)\n",
      "('positive\\\\142.png', 0)\n",
      "('positive\\\\143.png', 0)\n",
      "('positive\\\\144.png', 0)\n",
      "('positive\\\\145.png', 0)\n",
      "('positive\\\\146.png', 0)\n",
      "('positive\\\\147.png', 0)\n",
      "('positive\\\\148.png', 0)\n",
      "('positive\\\\149.png', 0)\n",
      "('positive\\\\150.png', 0)\n",
      "('positive\\\\151.png', 0)\n",
      "('positive\\\\152.png', 0)\n",
      "('positive\\\\153.png', 0)\n",
      "('positive\\\\154.png', 0)\n",
      "('positive\\\\155.png', 0)\n",
      "('positive\\\\156.png', 0)\n",
      "('positive\\\\157.png', 0)\n",
      "('positive\\\\158.png', 0)\n",
      "('positive\\\\159.png', 0)\n",
      "('positive\\\\160.png', 0)\n",
      "('positive\\\\161.png', 0)\n",
      "('positive\\\\162.png', 0)\n",
      "('positive\\\\163.png', 0)\n",
      "('positive\\\\164.png', 0)\n",
      "('positive\\\\165.png', 0)\n",
      "('positive\\\\166.png', 0)\n",
      "('positive\\\\167.png', 0)\n",
      "('positive\\\\168.png', 0)\n",
      "('positive\\\\169.png', 0)\n",
      "('positive\\\\170.png', 0)\n",
      "('positive\\\\171.png', 0)\n",
      "('positive\\\\172.png', 0)\n",
      "('positive\\\\173.png', 0)\n",
      "('positive\\\\174.png', 0)\n",
      "('positive\\\\175.png', 0)\n",
      "('positive\\\\176.png', 0)\n",
      "('positive\\\\177.png', 0)\n",
      "('positive\\\\178.png', 0)\n",
      "('positive\\\\179.png', 0)\n",
      "('positive\\\\180.png', 0)\n",
      "('positive\\\\181.png', 0)\n",
      "('positive\\\\182.png', 0)\n",
      "('positive\\\\183.png', 0)\n",
      "('positive\\\\184.png', 0)\n",
      "('positive\\\\185.png', 0)\n",
      "('positive\\\\186.png', 0)\n",
      "('positive\\\\187.png', 0)\n",
      "('positive\\\\188.png', 0)\n",
      "('positive\\\\189.png', 0)\n",
      "('positive\\\\190.png', 0)\n",
      "('positive\\\\191.png', 0)\n",
      "('positive\\\\192.png', 0)\n",
      "('positive\\\\193.png', 0)\n",
      "('positive\\\\194.png', 0)\n",
      "('positive\\\\195.png', 0)\n",
      "('positive\\\\196.png', 0)\n",
      "('positive\\\\197.png', 0)\n",
      "('positive\\\\198.png', 0)\n",
      "('positive\\\\199.png', 0)\n",
      "('positive\\\\200.png', 0)\n",
      "('positive\\\\201.png', 0)\n",
      "('positive\\\\202.png', 0)\n",
      "('positive\\\\203.png', 0)\n",
      "('positive\\\\204.png', 0)\n",
      "('positive\\\\205.png', 0)\n",
      "('positive\\\\206.png', 0)\n",
      "('positive\\\\207.png', 0)\n",
      "('positive\\\\208.png', 0)\n",
      "('positive\\\\209.png', 0)\n",
      "('positive\\\\210.png', 0)\n",
      "('positive\\\\211.png', 0)\n",
      "('positive\\\\212.png', 0)\n",
      "('positive\\\\213.png', 0)\n",
      "('positive\\\\214.png', 0)\n",
      "('positive\\\\215.png', 0)\n",
      "('positive\\\\216.png', 0)\n",
      "('positive\\\\217.png', 0)\n",
      "('positive\\\\218.png', 0)\n",
      "('positive\\\\219.png', 0)\n",
      "('negative\\\\000.png', 1)\n",
      "('negative\\\\001.png', 1)\n",
      "('negative\\\\002.png', 1)\n",
      "('negative\\\\003.png', 1)\n",
      "('negative\\\\004.png', 1)\n",
      "('negative\\\\005.png', 1)\n",
      "('negative\\\\006.png', 1)\n",
      "('negative\\\\007.png', 1)\n",
      "('negative\\\\008.png', 1)\n",
      "('negative\\\\009.png', 1)\n",
      "('negative\\\\010.png', 1)\n",
      "('negative\\\\011.png', 1)\n",
      "('negative\\\\012.png', 1)\n",
      "('negative\\\\013.png', 1)\n",
      "('negative\\\\014.png', 1)\n",
      "('negative\\\\015.png', 1)\n",
      "('negative\\\\016.png', 1)\n",
      "('negative\\\\017.png', 1)\n",
      "('negative\\\\018.png', 1)\n",
      "('negative\\\\019.png', 1)\n",
      "('negative\\\\020.png', 1)\n",
      "('negative\\\\021.png', 1)\n",
      "('negative\\\\022.png', 1)\n",
      "('negative\\\\023.png', 1)\n",
      "('negative\\\\024.png', 1)\n",
      "C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\train\\train_labels.csv にラベルリストを保存しました。\n"
     ]
    }
   ],
   "source": [
    "import os  # ファイルやフォルダ操作用モジュールを読み込みます\n",
    "import csv  # CSVファイルの読み書きライブラリを読み込みます\n",
    "\n",
    "base_folder = R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\train\"\n",
    "# 画像フォルダの親フォルダ名（例: dataset/良品, dataset/不良品）\n",
    "\n",
    "labels = []  # ファイル名とラベル（番号）を入れる空リストを作成\n",
    "\n",
    "# 良品と不良品のフォルダ名と対応ラベルを辞書で定義\n",
    "class_dict = {\"positive\": 0, \"negative\": 1}\n",
    "\n",
    "# 良品・不良品フォルダを順に処理します\n",
    "for class_name, label in class_dict.items():\n",
    "    folder_path = os.path.join(base_folder, class_name)  # 各クラスのフォルダパス\n",
    "    for filename in os.listdir(folder_path):  # フォルダ内のファイルをすべてチェック\n",
    "        if filename.endswith((\".jpg\", \".png\")):  # jpgやpngファイルを対象\n",
    "            file_path = os.path.join(class_name, filename)  # ファイル名をクラスフォルダ名と結合\n",
    "            labels.append((file_path, label))  # (ファイルパス, ラベル)の組をリストに追加\n",
    "\n",
    "# 結果を表示して確認\n",
    "for item in labels:\n",
    "    print(item)\n",
    "\n",
    "csv_filename =  R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\train\\train_labels.csv\"  # 保存するCSVファイル名\n",
    "\n",
    "with open(csv_filename, mode='w', newline='') as file:  # 書き込みモードでCSVファイルを開きます\n",
    "    writer = csv.writer(file)  # 書き込み用の準備をします\n",
    "    writer.writerow([\"filename\", \"label\"])  # 1行目にヘッダーを書き込みます（カラム名）\n",
    "    for item in labels:  # リストの中身を1つずつループ処理します\n",
    "        writer.writerow(item)  # ファイル名とラベルを1行ずつCSVに書き込みます\n",
    "\n",
    "print(f\"{csv_filename} にラベルリストを保存しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23fd96a3-7ec4-452c-aeb9-d16e100c04ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('positive\\\\000.png', 0)\n",
      "('positive\\\\001.png', 0)\n",
      "('positive\\\\002.png', 0)\n",
      "('positive\\\\003.png', 0)\n",
      "('positive\\\\004.png', 0)\n",
      "('positive\\\\005.png', 0)\n",
      "('positive\\\\006.png', 0)\n",
      "('positive\\\\007.png', 0)\n",
      "('positive\\\\008.png', 0)\n",
      "('positive\\\\009.png', 0)\n",
      "('positive\\\\010.png', 0)\n",
      "('positive\\\\011.png', 0)\n",
      "('positive\\\\012.png', 0)\n",
      "('positive\\\\013.png', 0)\n",
      "('positive\\\\014.png', 0)\n",
      "('positive\\\\015.png', 0)\n",
      "('positive\\\\016.png', 0)\n",
      "('positive\\\\017.png', 0)\n",
      "('positive\\\\018.png', 0)\n",
      "('positive\\\\019.png', 0)\n",
      "('positive\\\\020.png', 0)\n",
      "('positive\\\\021.png', 0)\n",
      "('positive\\\\022.png', 0)\n",
      "('positive\\\\023.png', 0)\n",
      "('positive\\\\024.png', 0)\n",
      "('positive\\\\025.png', 0)\n",
      "('positive\\\\026.png', 0)\n",
      "('positive\\\\027.png', 0)\n",
      "('positive\\\\028.png', 0)\n",
      "('positive\\\\029.png', 0)\n",
      "('positive\\\\030.png', 0)\n",
      "('positive\\\\031.png', 0)\n",
      "('positive\\\\032.png', 0)\n",
      "('positive\\\\033.png', 0)\n",
      "('positive\\\\034.png', 0)\n",
      "('positive\\\\035.png', 0)\n",
      "('positive\\\\036.png', 0)\n",
      "('positive\\\\037.png', 0)\n",
      "('positive\\\\038.png', 0)\n",
      "('positive\\\\039.png', 0)\n",
      "('positive\\\\040.png', 0)\n",
      "('positive\\\\041.png', 0)\n",
      "('positive\\\\042.png', 0)\n",
      "('positive\\\\043.png', 0)\n",
      "('positive\\\\044.png', 0)\n",
      "('positive\\\\045.png', 0)\n",
      "('positive\\\\046.png', 0)\n",
      "('positive\\\\047.png', 0)\n",
      "('positive\\\\048.png', 0)\n",
      "('positive\\\\049.png', 0)\n",
      "('positive\\\\050.png', 0)\n",
      "('positive\\\\051.png', 0)\n",
      "('positive\\\\052.png', 0)\n",
      "('positive\\\\053.png', 0)\n",
      "('positive\\\\054.png', 0)\n",
      "('positive\\\\055.png', 0)\n",
      "('positive\\\\056.png', 0)\n",
      "('positive\\\\057.png', 0)\n",
      "('positive\\\\058.png', 0)\n",
      "('positive\\\\059.png', 0)\n",
      "('positive\\\\060.png', 0)\n",
      "('positive\\\\061.png', 0)\n",
      "('positive\\\\062.png', 0)\n",
      "('positive\\\\063.png', 0)\n",
      "('positive\\\\064.png', 0)\n",
      "('positive\\\\065.png', 0)\n",
      "('positive\\\\066.png', 0)\n",
      "('positive\\\\067.png', 0)\n",
      "('positive\\\\068.png', 0)\n",
      "('positive\\\\069.png', 0)\n",
      "('positive\\\\070.png', 0)\n",
      "('positive\\\\071.png', 0)\n",
      "('positive\\\\072.png', 0)\n",
      "('positive\\\\073.png', 0)\n",
      "('positive\\\\074.png', 0)\n",
      "('positive\\\\075.png', 0)\n",
      "('positive\\\\076.png', 0)\n",
      "('positive\\\\077.png', 0)\n",
      "('positive\\\\078.png', 0)\n",
      "('positive\\\\079.png', 0)\n",
      "('positive\\\\080.png', 0)\n",
      "('positive\\\\081.png', 0)\n",
      "('positive\\\\082.png', 0)\n",
      "('positive\\\\083.png', 0)\n",
      "('positive\\\\084.png', 0)\n",
      "('positive\\\\085.png', 0)\n",
      "('positive\\\\086.png', 0)\n",
      "('positive\\\\087.png', 0)\n",
      "('positive\\\\088.png', 0)\n",
      "('positive\\\\089.png', 0)\n",
      "('positive\\\\090.png', 0)\n",
      "('positive\\\\091.png', 0)\n",
      "('positive\\\\092.png', 0)\n",
      "('positive\\\\093.png', 0)\n",
      "('positive\\\\094.png', 0)\n",
      "('positive\\\\095.png', 0)\n",
      "('positive\\\\096.png', 0)\n",
      "('positive\\\\097.png', 0)\n",
      "('positive\\\\098.png', 0)\n",
      "('positive\\\\099.png', 0)\n",
      "('positive\\\\100.png', 0)\n",
      "('negative\\\\00013.png', 1)\n",
      "('negative\\\\00023.png', 1)\n",
      "('negative\\\\0003.png', 1)\n",
      "('negative\\\\00113.png', 1)\n",
      "('negative\\\\00123.png', 1)\n",
      "('negative\\\\0013.png', 1)\n",
      "('negative\\\\00213.png', 1)\n",
      "('negative\\\\00223.png', 1)\n",
      "('negative\\\\0023.png', 1)\n",
      "('negative\\\\00313.png', 1)\n",
      "('negative\\\\00323.png', 1)\n",
      "('negative\\\\0033.png', 1)\n",
      "('negative\\\\00413.png', 1)\n",
      "('negative\\\\00423.png', 1)\n",
      "('negative\\\\0043.png', 1)\n",
      "('negative\\\\00513.png', 1)\n",
      "('negative\\\\00523.png', 1)\n",
      "('negative\\\\0053.png', 1)\n",
      "('negative\\\\00613.png', 1)\n",
      "('negative\\\\00623.png', 1)\n",
      "('negative\\\\0063.png', 1)\n",
      "('negative\\\\00713.png', 1)\n",
      "('negative\\\\00723.png', 1)\n",
      "('negative\\\\0073.png', 1)\n",
      "('negative\\\\00813.png', 1)\n",
      "('negative\\\\00823.png', 1)\n",
      "('negative\\\\0083.png', 1)\n",
      "('negative\\\\00913.png', 1)\n",
      "('negative\\\\00923.png', 1)\n",
      "('negative\\\\0093.png', 1)\n",
      "('negative\\\\01013.png', 1)\n",
      "('negative\\\\01023.png', 1)\n",
      "('negative\\\\0103.png', 1)\n",
      "('negative\\\\01113.png', 1)\n",
      "('negative\\\\01123.png', 1)\n",
      "('negative\\\\0113.png', 1)\n",
      "('negative\\\\01213.png', 1)\n",
      "('negative\\\\01223.png', 1)\n",
      "('negative\\\\0123.png', 1)\n",
      "('negative\\\\01313.png', 1)\n",
      "('negative\\\\01323.png', 1)\n",
      "('negative\\\\0133.png', 1)\n",
      "('negative\\\\01413.png', 1)\n",
      "('negative\\\\01423.png', 1)\n",
      "('negative\\\\0143.png', 1)\n",
      "('negative\\\\01513.png', 1)\n",
      "('negative\\\\01523.png', 1)\n",
      "('negative\\\\0153.png', 1)\n",
      "('negative\\\\01613.png', 1)\n",
      "('negative\\\\01623.png', 1)\n",
      "('negative\\\\0163.png', 1)\n",
      "('negative\\\\01713.png', 1)\n",
      "('negative\\\\01723.png', 1)\n",
      "('negative\\\\0173.png', 1)\n",
      "('negative\\\\01813.png', 1)\n",
      "('negative\\\\01823.png', 1)\n",
      "('negative\\\\0183.png', 1)\n",
      "('negative\\\\01913.png', 1)\n",
      "('negative\\\\01923.png', 1)\n",
      "('negative\\\\0193.png', 1)\n",
      "('negative\\\\02013.png', 1)\n",
      "('negative\\\\02023.png', 1)\n",
      "('negative\\\\0203.png', 1)\n",
      "('negative\\\\02113.png', 1)\n",
      "('negative\\\\02123.png', 1)\n",
      "('negative\\\\0213.png', 1)\n",
      "('negative\\\\02213.png', 1)\n",
      "('negative\\\\02223.png', 1)\n",
      "C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\val\\val_labels.csv にラベルリストを保存しました。\n"
     ]
    }
   ],
   "source": [
    "import os  # ファイルやフォルダ操作用モジュールを読み込みます\n",
    "import csv  # CSVファイルの読み書きライブラリを読み込みます\n",
    "\n",
    "base_folder = R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\val\"\n",
    "# 画像フォルダの親フォルダ名（例: dataset/良品, dataset/不良品）\n",
    "\n",
    "labels = []  # ファイル名とラベル（番号）を入れる空リストを作成\n",
    "\n",
    "# 良品と不良品のフォルダ名と対応ラベルを辞書で定義\n",
    "class_dict = {\"positive\": 0, \"negative\": 1}\n",
    "\n",
    "# 良品・不良品フォルダを順に処理します\n",
    "for class_name, label in class_dict.items():\n",
    "    folder_path = os.path.join(base_folder, class_name)  # 各クラスのフォルダパス\n",
    "    for filename in os.listdir(folder_path):  # フォルダ内のファイルをすべてチェック\n",
    "        if filename.endswith((\".jpg\", \".png\")):  # jpgやpngファイルを対象\n",
    "            file_path = os.path.join(class_name, filename)  # ファイル名をクラスフォルダ名と結合\n",
    "            labels.append((file_path, label))  # (ファイルパス, ラベル)の組をリストに追加\n",
    "\n",
    "# 結果を表示して確認\n",
    "for item in labels:\n",
    "    print(item)\n",
    "\n",
    "csv_filename =  R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\val\\val_labels.csv\"  # 保存するCSVファイル名\n",
    "\n",
    "with open(csv_filename, mode='w', newline='') as file:  # 書き込みモードでCSVファイルを開きます\n",
    "    writer = csv.writer(file)  # 書き込み用の準備をします\n",
    "    writer.writerow([\"filename\", \"label\"])  # 1行目にヘッダーを書き込みます（カラム名）\n",
    "    for item in labels:  # リストの中身を1つずつループ処理します\n",
    "        writer.writerow(item)  # ファイル名とラベルを1行ずつCSVに書き込みます\n",
    "\n",
    "print(f\"{csv_filename} にラベルリストを保存しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9382a7e6-5acf-4066-8e1c-cbaf24bb5116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVから読み込んだリスト: [('positive\\\\101.png', 0), ('positive\\\\102.png', 0), ('positive\\\\103.png', 0), ('positive\\\\104.png', 0), ('positive\\\\105.png', 0), ('positive\\\\106.png', 0), ('positive\\\\107.png', 0), ('positive\\\\108.png', 0), ('positive\\\\109.png', 0), ('positive\\\\110.png', 0), ('positive\\\\111.png', 0), ('positive\\\\112.png', 0), ('positive\\\\113.png', 0), ('positive\\\\114.png', 0), ('positive\\\\115.png', 0), ('positive\\\\116.png', 0), ('positive\\\\117.png', 0), ('positive\\\\118.png', 0), ('positive\\\\119.png', 0), ('positive\\\\120.png', 0), ('positive\\\\121.png', 0), ('positive\\\\122.png', 0), ('positive\\\\123.png', 0), ('positive\\\\124.png', 0), ('positive\\\\125.png', 0), ('positive\\\\126.png', 0), ('positive\\\\127.png', 0), ('positive\\\\128.png', 0), ('positive\\\\129.png', 0), ('positive\\\\130.png', 0), ('positive\\\\131.png', 0), ('positive\\\\132.png', 0), ('positive\\\\133.png', 0), ('positive\\\\134.png', 0), ('positive\\\\135.png', 0), ('positive\\\\136.png', 0), ('positive\\\\137.png', 0), ('positive\\\\138.png', 0), ('positive\\\\139.png', 0), ('positive\\\\140.png', 0), ('positive\\\\141.png', 0), ('positive\\\\142.png', 0), ('positive\\\\143.png', 0), ('positive\\\\144.png', 0), ('positive\\\\145.png', 0), ('positive\\\\146.png', 0), ('positive\\\\147.png', 0), ('positive\\\\148.png', 0), ('positive\\\\149.png', 0), ('positive\\\\150.png', 0), ('positive\\\\151.png', 0), ('positive\\\\152.png', 0), ('positive\\\\153.png', 0), ('positive\\\\154.png', 0), ('positive\\\\155.png', 0), ('positive\\\\156.png', 0), ('positive\\\\157.png', 0), ('positive\\\\158.png', 0), ('positive\\\\159.png', 0), ('positive\\\\160.png', 0), ('positive\\\\161.png', 0), ('positive\\\\162.png', 0), ('positive\\\\163.png', 0), ('positive\\\\164.png', 0), ('positive\\\\165.png', 0), ('positive\\\\166.png', 0), ('positive\\\\167.png', 0), ('positive\\\\168.png', 0), ('positive\\\\169.png', 0), ('positive\\\\170.png', 0), ('positive\\\\171.png', 0), ('positive\\\\172.png', 0), ('positive\\\\173.png', 0), ('positive\\\\174.png', 0), ('positive\\\\175.png', 0), ('positive\\\\176.png', 0), ('positive\\\\177.png', 0), ('positive\\\\178.png', 0), ('positive\\\\179.png', 0), ('positive\\\\180.png', 0), ('positive\\\\181.png', 0), ('positive\\\\182.png', 0), ('positive\\\\183.png', 0), ('positive\\\\184.png', 0), ('positive\\\\185.png', 0), ('positive\\\\186.png', 0), ('positive\\\\187.png', 0), ('positive\\\\188.png', 0), ('positive\\\\189.png', 0), ('positive\\\\190.png', 0), ('positive\\\\191.png', 0), ('positive\\\\192.png', 0), ('positive\\\\193.png', 0), ('positive\\\\194.png', 0), ('positive\\\\195.png', 0), ('positive\\\\196.png', 0), ('positive\\\\197.png', 0), ('positive\\\\198.png', 0), ('positive\\\\199.png', 0), ('positive\\\\200.png', 0), ('positive\\\\201.png', 0), ('positive\\\\202.png', 0), ('positive\\\\203.png', 0), ('positive\\\\204.png', 0), ('positive\\\\205.png', 0), ('positive\\\\206.png', 0), ('positive\\\\207.png', 0), ('positive\\\\208.png', 0), ('positive\\\\209.png', 0), ('positive\\\\210.png', 0), ('positive\\\\211.png', 0), ('positive\\\\212.png', 0), ('positive\\\\213.png', 0), ('positive\\\\214.png', 0), ('positive\\\\215.png', 0), ('positive\\\\216.png', 0), ('positive\\\\217.png', 0), ('positive\\\\218.png', 0), ('positive\\\\219.png', 0), ('negative\\\\000.png', 1), ('negative\\\\001.png', 1), ('negative\\\\002.png', 1), ('negative\\\\003.png', 1), ('negative\\\\004.png', 1), ('negative\\\\005.png', 1), ('negative\\\\006.png', 1), ('negative\\\\007.png', 1), ('negative\\\\008.png', 1), ('negative\\\\009.png', 1), ('negative\\\\010.png', 1), ('negative\\\\011.png', 1), ('negative\\\\012.png', 1), ('negative\\\\013.png', 1), ('negative\\\\014.png', 1), ('negative\\\\015.png', 1), ('negative\\\\016.png', 1), ('negative\\\\017.png', 1), ('negative\\\\018.png', 1), ('negative\\\\019.png', 1), ('negative\\\\020.png', 1), ('negative\\\\021.png', 1), ('negative\\\\022.png', 1), ('negative\\\\023.png', 1), ('negative\\\\024.png', 1)]\n"
     ]
    }
   ],
   "source": [
    "import csv  # CSV読み込みに必要なモジュール\n",
    "\n",
    "csv_filename = R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\train\\train_labels.csv\"  # 読み込むCSVファイル名\n",
    "\n",
    "labels_loaded = []  # 読み込んだ内容を入れる空リスト\n",
    "\n",
    "with open(csv_filename, mode='r') as file:  # 読み込みモードで開きます\n",
    "    reader = csv.reader(file)  # 読み込み用の準備\n",
    "    next(reader)  # 1行目のヘッダーをスキップします\n",
    "    for row in reader:  # 2行目以降を1行ずつ処理\n",
    "        filename = row[0]  # 1列目がファイル名\n",
    "        label = int(row[1])  # 2列目がラベル（文字列なのでintに変換）\n",
    "        labels_loaded.append((filename, label))  # タプルとしてリストに追加\n",
    "\n",
    "print(\"CSVから読み込んだリスト:\", labels_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "254b49c5-f78e-4c7d-8956-53a6e6f3d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVから読み込んだリスト: [('positive\\\\000.png', 0), ('positive\\\\001.png', 0), ('positive\\\\002.png', 0), ('positive\\\\003.png', 0), ('positive\\\\004.png', 0), ('positive\\\\005.png', 0), ('positive\\\\006.png', 0), ('positive\\\\007.png', 0), ('positive\\\\008.png', 0), ('positive\\\\009.png', 0), ('positive\\\\010.png', 0), ('positive\\\\011.png', 0), ('positive\\\\012.png', 0), ('positive\\\\013.png', 0), ('positive\\\\014.png', 0), ('positive\\\\015.png', 0), ('positive\\\\016.png', 0), ('positive\\\\017.png', 0), ('positive\\\\018.png', 0), ('positive\\\\019.png', 0), ('positive\\\\020.png', 0), ('positive\\\\021.png', 0), ('positive\\\\022.png', 0), ('positive\\\\023.png', 0), ('positive\\\\024.png', 0), ('positive\\\\025.png', 0), ('positive\\\\026.png', 0), ('positive\\\\027.png', 0), ('positive\\\\028.png', 0), ('positive\\\\029.png', 0), ('positive\\\\030.png', 0), ('positive\\\\031.png', 0), ('positive\\\\032.png', 0), ('positive\\\\033.png', 0), ('positive\\\\034.png', 0), ('positive\\\\035.png', 0), ('positive\\\\036.png', 0), ('positive\\\\037.png', 0), ('positive\\\\038.png', 0), ('positive\\\\039.png', 0), ('positive\\\\040.png', 0), ('positive\\\\041.png', 0), ('positive\\\\042.png', 0), ('positive\\\\043.png', 0), ('positive\\\\044.png', 0), ('positive\\\\045.png', 0), ('positive\\\\046.png', 0), ('positive\\\\047.png', 0), ('positive\\\\048.png', 0), ('positive\\\\049.png', 0), ('positive\\\\050.png', 0), ('positive\\\\051.png', 0), ('positive\\\\052.png', 0), ('positive\\\\053.png', 0), ('positive\\\\054.png', 0), ('positive\\\\055.png', 0), ('positive\\\\056.png', 0), ('positive\\\\057.png', 0), ('positive\\\\058.png', 0), ('positive\\\\059.png', 0), ('positive\\\\060.png', 0), ('positive\\\\061.png', 0), ('positive\\\\062.png', 0), ('positive\\\\063.png', 0), ('positive\\\\064.png', 0), ('positive\\\\065.png', 0), ('positive\\\\066.png', 0), ('positive\\\\067.png', 0), ('positive\\\\068.png', 0), ('positive\\\\069.png', 0), ('positive\\\\070.png', 0), ('positive\\\\071.png', 0), ('positive\\\\072.png', 0), ('positive\\\\073.png', 0), ('positive\\\\074.png', 0), ('positive\\\\075.png', 0), ('positive\\\\076.png', 0), ('positive\\\\077.png', 0), ('positive\\\\078.png', 0), ('positive\\\\079.png', 0), ('positive\\\\080.png', 0), ('positive\\\\081.png', 0), ('positive\\\\082.png', 0), ('positive\\\\083.png', 0), ('positive\\\\084.png', 0), ('positive\\\\085.png', 0), ('positive\\\\086.png', 0), ('positive\\\\087.png', 0), ('positive\\\\088.png', 0), ('positive\\\\089.png', 0), ('positive\\\\090.png', 0), ('positive\\\\091.png', 0), ('positive\\\\092.png', 0), ('positive\\\\093.png', 0), ('positive\\\\094.png', 0), ('positive\\\\095.png', 0), ('positive\\\\096.png', 0), ('positive\\\\097.png', 0), ('positive\\\\098.png', 0), ('positive\\\\099.png', 0), ('positive\\\\100.png', 0), ('negative\\\\00013.png', 1), ('negative\\\\00023.png', 1), ('negative\\\\0003.png', 1), ('negative\\\\00113.png', 1), ('negative\\\\00123.png', 1), ('negative\\\\0013.png', 1), ('negative\\\\00213.png', 1), ('negative\\\\00223.png', 1), ('negative\\\\0023.png', 1), ('negative\\\\00313.png', 1), ('negative\\\\00323.png', 1), ('negative\\\\0033.png', 1), ('negative\\\\00413.png', 1), ('negative\\\\00423.png', 1), ('negative\\\\0043.png', 1), ('negative\\\\00513.png', 1), ('negative\\\\00523.png', 1), ('negative\\\\0053.png', 1), ('negative\\\\00613.png', 1), ('negative\\\\00623.png', 1), ('negative\\\\0063.png', 1), ('negative\\\\00713.png', 1), ('negative\\\\00723.png', 1), ('negative\\\\0073.png', 1), ('negative\\\\00813.png', 1), ('negative\\\\00823.png', 1), ('negative\\\\0083.png', 1), ('negative\\\\00913.png', 1), ('negative\\\\00923.png', 1), ('negative\\\\0093.png', 1), ('negative\\\\01013.png', 1), ('negative\\\\01023.png', 1), ('negative\\\\0103.png', 1), ('negative\\\\01113.png', 1), ('negative\\\\01123.png', 1), ('negative\\\\0113.png', 1), ('negative\\\\01213.png', 1), ('negative\\\\01223.png', 1), ('negative\\\\0123.png', 1), ('negative\\\\01313.png', 1), ('negative\\\\01323.png', 1), ('negative\\\\0133.png', 1), ('negative\\\\01413.png', 1), ('negative\\\\01423.png', 1), ('negative\\\\0143.png', 1), ('negative\\\\01513.png', 1), ('negative\\\\01523.png', 1), ('negative\\\\0153.png', 1), ('negative\\\\01613.png', 1), ('negative\\\\01623.png', 1), ('negative\\\\0163.png', 1), ('negative\\\\01713.png', 1), ('negative\\\\01723.png', 1), ('negative\\\\0173.png', 1), ('negative\\\\01813.png', 1), ('negative\\\\01823.png', 1), ('negative\\\\0183.png', 1), ('negative\\\\01913.png', 1), ('negative\\\\01923.png', 1), ('negative\\\\0193.png', 1), ('negative\\\\02013.png', 1), ('negative\\\\02023.png', 1), ('negative\\\\0203.png', 1), ('negative\\\\02113.png', 1), ('negative\\\\02123.png', 1), ('negative\\\\0213.png', 1), ('negative\\\\02213.png', 1), ('negative\\\\02223.png', 1)]\n"
     ]
    }
   ],
   "source": [
    "import csv  # CSV読み込みに必要なモジュール\n",
    "\n",
    "csv_filename = R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\val\\val_labels.csv\"\n",
    "# 読み込むCSVファイル名\n",
    "\n",
    "labels_loaded = []  # 読み込んだ内容を入れる空リスト\n",
    "\n",
    "with open(csv_filename, mode='r') as file:  # 読み込みモードで開きます\n",
    "    reader = csv.reader(file)  # 読み込み用の準備\n",
    "    next(reader)  # 1行目のヘッダーをスキップします\n",
    "    for row in reader:  # 2行目以降を1行ずつ処理\n",
    "        filename = row[0]  # 1列目がファイル名\n",
    "        label = int(row[1])  # 2列目がラベル（文字列なのでintに変換）\n",
    "        labels_loaded.append((filename, label))  # タプルとしてリストに追加\n",
    "\n",
    "print(\"CSVから読み込んだリスト:\", labels_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e89dcc6-c032-499d-bd1c-9abce695ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=980000, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch  # PyTorch本体を読み込み\n",
    "import torch.nn as nn  # ニューラルネットワークモジュール\n",
    "import torch.nn.functional as F  # 活性化関数などの関数群\n",
    "\n",
    "# nn.Moduleを継承したクラスでモデルを定義\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()  # 親クラスの初期化\n",
    "\n",
    "        # 畳み込み層1：入力チャネル3（RGB画像）、出力チャネル16、カーネルサイズ3\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "\n",
    "        # プーリング層：2×2の最大プーリング（画像サイズを半分にする）\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # 畳み込み層2：16チャネルから32チャネルへ\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "\n",
    "        # 全結合層：32チャネル、175×175サイズの特徴量→出力クラス数2（良品/不良品）\n",
    "        self.fc1 = nn.Linear(32 * 175 * 175, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # conv1→ReLU→pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # conv2→ReLU→pooling\n",
    "        x = x.view(-1, 32 * 175 * 175)  # 1次元に展開\n",
    "        x = self.fc1(x)  # 全結合層を通す\n",
    "        return x\n",
    "\n",
    "# モデルのインスタンス作成\n",
    "model = SimpleCNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff107d76-a722-4d2f-8b3e-db746e23ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AtsukiSakamoto\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AtsukiSakamoto\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models  # torchvisionのモデル読み込み\n",
    "\n",
    "# 事前学習済みResNet18をロードし、出力層を2クラス用に変更\n",
    "resnet = models.resnet18(pretrained=True)  # ResNet18の事前学習モデルを使う\n",
    "num_ftrs = resnet.fc.in_features  # 最終全結合層の入力特徴数を取得\n",
    "resnet.fc = nn.Linear(num_ftrs, 2)  # 出力層を2クラスに置き換え\n",
    "\n",
    "print(resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f432db3c-567e-4c61-a21b-bf64f37f0e78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):  \u001b[38;5;66;03m# 1回の学習を1エポックと呼ぶ。これを繰り返す\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# 1エポックの損失合計を初期化\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loader\u001b[49m:  \u001b[38;5;66;03m# データローダーからバッチごとにデータを取得\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# 前の学習ステップの勾配をリセット\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)  \u001b[38;5;66;03m# モデルに画像を入力し、予測結果を取得\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import torch  # PyTorch本体\n",
    "import torch.nn as nn  # ニューラルネットワークのレイヤーを使うため\n",
    "import torch.optim as optim  # モデルを最適化（勾配降下法など）のため\n",
    "from torchvision import transforms  # 画像の前処理用\n",
    "from torch.utils.data import DataLoader  # データを小分けにして処理するため\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 分類向けの損失関数（予測と本物の違いを数値化）\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 学習率0.001のAdam最適化\n",
    "\n",
    "num_epochs = 10  # 学習を繰り返す回数\n",
    "\n",
    "for epoch in range(num_epochs):  # 1回の学習を1エポックと呼ぶ。これを繰り返す\n",
    "    running_loss = 0.0  # 1エポックの損失合計を初期化\n",
    "    for inputs, labels in train_loader:  # データローダーからバッチごとにデータを取得\n",
    "        optimizer.zero_grad()  # 前の学習ステップの勾配をリセット\n",
    "\n",
    "        outputs = model(inputs)  # モデルに画像を入力し、予測結果を取得\n",
    "\n",
    "        loss = criterion(outputs, labels)  # 予測と正解ラベルの誤差を計算\n",
    "\n",
    "        loss.backward()  # 誤差を基に勾配を計算（逆伝播）\n",
    "\n",
    "        optimizer.step()  # 勾配を使ってモデルのパラメータを更新\n",
    "\n",
    "        running_loss += loss.item()  # 今回の損失を合計に加算\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss:.4f}')  # エポックごとの損失を表示\n",
    "print('学習終了')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3518c490-2532-4bab-8144-db29ad2e613c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 指定されたパスが見つかりません。: 'C:\\\\work\\\\mazda_ai_portfolio\\\\mspc_001\\\\metal_nut\\\\metal_nut\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m      7\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      8\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)),  \u001b[38;5;66;03m# 画像サイズを64x64に統一します\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),  \u001b[38;5;66;03m# 画像をテンソル（数字の配列）に変換します\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m,), (\u001b[38;5;241m0.5\u001b[39m,)),  \u001b[38;5;66;03m# ピクセルの値を標準化します\u001b[39;00m\n\u001b[0;32m     11\u001b[0m ])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 画像データセットをフォルダから読み込み、学習用と検証用に分けます\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mwork\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmazda_ai_portfolio\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmspc_001\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmetal_nut\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmetal_nut\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwork\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmazda_ai_portfolio\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmspc_001\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmetal_nut\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmetal_nut\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m     17\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# バッチ32でデータを読み込み\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m ):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[0;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_classes\u001b[39m(directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 指定されたパスが見つかりません。: 'C:\\\\work\\\\mazda_ai_portfolio\\\\mspc_001\\\\metal_nut\\\\metal_nut\\\\train'"
     ]
    }
   ],
   "source": [
    "import torch  # PyTorchのライブラリを読み込みます\n",
    "import torch.nn as nn  # ニューラルネットワークのモジュールを使います\n",
    "import torch.optim as optim  # 最適化アルゴリズムを使います\n",
    "from torchvision import datasets, transforms  # 画像データ読み込み・前処理を簡単にします\n",
    "\n",
    "# 画像の前処理（リサイズ、テンソル化、正規化）\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # 画像サイズを64x64に統一します\n",
    "    transforms.ToTensor(),  # 画像をテンソル（数字の配列）に変換します\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # ピクセルの値を標準化します\n",
    "])\n",
    "\n",
    "# 画像データセットをフォルダから読み込み、学習用と検証用に分けます\n",
    "train_dataset = datasets.ImageFolder(R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(R\"C:\\work\\mazda_ai_portfolio\\mspc_001\\metal_nut\\metal_nut\\val\", transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)  # バッチ32でデータを読み込み\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# CNNモデルのクラスを定義（畳み込み層＋全結合層の簡単な構造）\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()  # 親クラスの初期化\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1)  # 3チャンネル→16チャンネルの畳み込み。カーネルサイズは3\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 2x2の最大プーリングでサイズ半減\n",
    "        self.fc1 = nn.Linear(16*31*31, 2)  # 全結合層。出力2はクラス数（例：良品/不良品）\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # 畳み込み→ReLU→プーリング\n",
    "        x = x.view(-1, 16*31*31)  # テンソルを1次元に変換\n",
    "        x = self.fc1(x)  # 全結合層に入力\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()  # モデルのインスタンス作成\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 損失関数（分類用の交差エントロピー）\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 最適化アルゴリズム（Adam）を設定\n",
    "\n",
    "# 1エポックの学習ループ例\n",
    "for images, labels in train_loader:\n",
    "    optimizer.zero_grad()  # 勾配の初期化\n",
    "    outputs = model(images)  # モデルで予測を得る\n",
    "    loss = criterion(outputs, labels)  # 予測と正解ラベルの誤差計算\n",
    "    loss.backward()  # 誤差を逆伝播し勾配を計算\n",
    "    optimizer.step()  # パラメータ更新\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 分類向けの損失関数（予測と本物の違いを数値化）\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 学習率0.001のAdam最適化\n",
    "\n",
    "num_epochs = 10 # 学習を繰り返す回数\n",
    "\n",
    "for epoch in range(num_epochs):  # 1回の学習を1エポックと呼ぶ。これを繰り返す\n",
    "    running_loss = 0.0  # 1エポックの損失合計を初期化\n",
    "    for inputs, labels in train_loader:  # データローダーからバッチごとにデータを取得\n",
    "        optimizer.zero_grad()  # 前の学習ステップの勾配をリセット\n",
    "\n",
    "        outputs = model(inputs)  # モデルに画像を入力し、予測結果を取得\n",
    "\n",
    "        loss = criterion(outputs, labels)  # 予測と正解ラベルの誤差を計算\n",
    "\n",
    "        loss.backward()  # 誤差を基に勾配を計算（逆伝播）\n",
    "\n",
    "        optimizer.step()  # 勾配を使ってモデルのパラメータを更新\n",
    "\n",
    "        running_loss += loss.item()  # 今回の損失を合計に加算\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss:.4f}')  # エポックごとの損失を表示\n",
    "print('学習終了')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c4d283d-65a1-4cc5-a4bb-9be6e07b2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データの正解率: 0.7153\n",
      "混同行列:\n",
      "[[39 29]\n",
      " [10 59]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "適合率： 0.6704545454545454\n",
      "再現率： 0.855072463768116\n",
      "F値： 0.7515923566878981\n"
     ]
    }
   ],
   "source": [
    "import torch  # PyTorch本体\n",
    "import torch.nn.functional as F  # 活性化関数など\n",
    "from sklearn.metrics import confusion_matrix  # 混同行列計算用\n",
    "import matplotlib.pyplot as plt  # 結果をグラフ化するため（任意）\n",
    "import matplotlib\n",
    "# 日本語を表示できるフォントに設定（Windowsなら例として'MS Gothic'）\n",
    "matplotlib.rcParams['font.family'] = 'MS Gothic'  \n",
    "\n",
    "model.eval()  # 評価モードに切り替え（学習時とは違い勾配計算しない設定）\n",
    "\n",
    "all_preds = []  # 予測結果をためるリスト\n",
    "all_labels = []  # 正解ラベルをためるリスト\n",
    "\n",
    "with torch.no_grad():  # 勾配計算を止めて計算を軽くする\n",
    "    for inputs, labels in val_loader:  # 検証用データをバッチで取得\n",
    "        outputs = model(inputs)  # モデルに入力して予測結果を得る\n",
    "        probs = F.softmax(outputs, dim=1)  # 出力を確率に変換\n",
    "        preds = torch.argmax(probs, dim=1)  # 一番高い確率のクラスを選ぶ\n",
    "        all_preds.extend(preds.cpu().numpy())  # CPUに戻しリストに追加\n",
    "        all_labels.extend(labels.cpu().numpy())  # 正解ラベルもリストに追加\n",
    "\n",
    "# 正解率を計算\n",
    "correct = sum(p == t for p, t in zip(all_preds, all_labels))\n",
    "accuracy = correct / len(all_labels)\n",
    "print(f\"検証データの正解率: {accuracy:.4f}\")\n",
    "\n",
    "# 混同行列を計算・表示\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"混同行列:\")\n",
    "print(cm)\n",
    "\n",
    "# （必要なら）混同行列をグラフで表示\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"予測ラベル\")\n",
    "plt.ylabel(\"正解ラベル\")\n",
    "plt.title(\"混同行列\")\n",
    "plt.show()\n",
    "\n",
    "# --- ここから改良例 ---\n",
    "# ハイパーパラメータ調整やレイヤー追加は別途モデル定義部分で行い再学習します\n",
    "\n",
    "# 例：学習率の変更\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"適合率：\", precision_score(all_labels, all_preds))\n",
    "print(\"再現率：\", recall_score(all_labels, all_preds))\n",
    "print(\"F値：\", f1_score(all_labels, all_preds))\n",
    "\n",
    "# データ拡張例\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ハイパーパラメータ変更例\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "# 転移学習の微調整例\n",
    "# model.fc = nn.Linear(in_features, num_classes)  # 最終層を置き換え\n",
    "# 再び訓練ループで最適化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f9f7e-3c4c-4b2d-a188-a7e851cabb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-env)",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
